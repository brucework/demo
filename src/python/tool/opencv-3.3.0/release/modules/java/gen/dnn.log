ok: class CLASS ::.Dnn : , name: Dnn, base: 

===== Common header : /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/misc/java/src/cpp/dnn_converters.hpp =====


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn.hpp =====
Namespaces: set([])
Ignore header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn.hpp


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/shape_utils.hpp =====
Namespaces: set([u'cv.dnn.<unnamed>', u'cv.dnn', u'cv'])
Ignore header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/shape_utils.hpp


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/layer.details.hpp =====
Namespaces: set([u'cv.dnn.<unnamed>', u'cv.dnn', u'cv', u'cv.dnn.details'])
Ignore header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/layer.details.hpp


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/all_layers.hpp =====
Namespaces: set([u'cv.dnn.<unnamed>', u'cv.dnn', u'cv', u'cv.dnn.details'])

--- Incoming ---
[u'const cv.dnn.LRNLayer.CHANNEL_NRM', '0', [], [], None, '']
class not found: CONST CHANNEL_NRM=0

--- Incoming ---
[u'const cv.dnn.LRNLayer.SPATIAL_NRM', '1', [], [], None, '']
class not found: CONST SPATIAL_NRM=1

--- Incoming ---
[u'const cv.dnn.PoolingLayer.MAX', '0', [], [], None, '']
class not found: CONST MAX=0

--- Incoming ---
[u'const cv.dnn.PoolingLayer.AVE', '1', [], [], None, '']
class not found: CONST AVE=1

--- Incoming ---
[u'const cv.dnn.PoolingLayer.STOCHASTIC', '2', [], [], None, '']
class not found: CONST STOCHASTIC=2

--- Incoming ---
[u'const cv.dnn.EltwiseLayer.PROD', u'0', [], [], None, '']
class not found: CONST PROD=0

--- Incoming ---
[u'const cv.dnn.EltwiseLayer.SUM', u'1', [], [], None, '']
class not found: CONST SUM=1

--- Incoming ---
[u'const cv.dnn.EltwiseLayer.MAX', u'2', [], [], None, '']
class not found: CONST MAX=2


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/dnn.hpp =====
Namespaces: set([u'cv.dnn.experimental_dnn_v1', u'cv.dnn.<unnamed>', u'cv.dnn', u'cv', u'cv.dnn.details'])

--- Incoming ---
[u'const cv.dnn.DNN_BACKEND_DEFAULT', '0', [], [], None, '']
ok: CONST DNN_BACKEND_DEFAULT=0

--- Incoming ---
[u'const cv.dnn.DNN_BACKEND_HALIDE', '1', [], [], None, '']
ok: CONST DNN_BACKEND_HALIDE=1

--- Incoming ---
[u'const cv.dnn.DNN_TARGET_CPU', '0', [], [], None, '']
ok: CONST DNN_TARGET_CPU=0

--- Incoming ---
[u'const cv.dnn.DNN_TARGET_OPENCL', '1', [], [], None, '']
ok: CONST DNN_TARGET_OPENCL=1

--- Incoming ---
[   u'class cv.dnn.Layer',
    ': cv::Algorithm',
    [],
    [   [u'vector_Mat', u'blobs', '', ['/RW']],
        [u'String', u'name', '', []],
        [u'String', u'type', '', []]],
    None,
    u'@brief This interface class allows to build new Layers - are building blocks of networks.\n*\n* Each class, derived from Layer, must implement allocate() methods to declare own outputs and forward() to compute outputs.\n* Also before using the new layer into networks you must register your layer by using one of @ref dnnLayerFactory "LayerFactory" macros.']
ok: class CLASS cv.dnn::.Layer : Algorithm, name: Layer, base: Algorithm

--- Incoming ---
[   u'cv.dnn.Layer.finalize',
    u'void',
    [],
    [   [u'vector_Mat', u'inputs', u'', []],
        [u'vector_Mat', u'outputs', u'', ['/O']]],
    u'void',
    u'@brief @overload']
ok: FUNC <void cv.dnn.Layer.finalize [ARG vector_Mat inputs=, ARG vector_Mat outputs=]>

--- Incoming ---
[   u'cv.dnn.Layer.finalize',
    u'vector_Mat',
    [],
    [[u'vector_Mat', u'inputs', u'', []]],
    u'std::vector<Mat>',
    u'@brief @overload']
ok: FUNC <vector_Mat cv.dnn.Layer.finalize [ARG vector_Mat inputs=]>

--- Incoming ---
[   u'cv.dnn.Layer.forward',
    u'void',
    [],
    [   [u'vector_Mat', u'inputs', u'', []],
        [u'vector_Mat', u'outputs', u'', ['/IO']],
        [u'vector_Mat', u'internals', u'', ['/IO']]],
    u'void',
    u'@brief @overload']
ok: FUNC <void cv.dnn.Layer.forward [ARG vector_Mat inputs=, ARG vector_Mat outputs=, ARG vector_Mat internals=]>

--- Incoming ---
[   u'cv.dnn.Layer.run',
    u'void',
    [],
    [   [u'vector_Mat', u'inputs', u'', []],
        [u'vector_Mat', u'outputs', u'', ['/O']],
        [u'vector_Mat', u'internals', u'', ['/IO']]],
    u'void',
    u'@brief Allocates layer and computes output.']
ok: FUNC <void cv.dnn.Layer.run [ARG vector_Mat inputs=, ARG vector_Mat outputs=, ARG vector_Mat internals=]>

--- Incoming ---
[   u'class cv.dnn.Net',
    '',
    ['/Simple'],
    [],
    None,
    u'@brief This class allows to create and manipulate comprehensive artificial neural networks.\n*\n* Neural network is presented as directed acyclic graph (DAG), where vertices are Layer instances,\n* and edges specify relationships between layers inputs and outputs.\n*\n* Each network layer has unique integer id and unique string name inside its network.\n* LayerId can store either layer name or layer id.\n*\n* This class supports reference counting of its instances, i. e. copies point to the same instance.']
ok: class CLASS cv.dnn::.Net : , name: Net, base: 

--- Incoming ---
[u'cv.dnn.Net.Net', '', [], [], None, '']
ok: FUNC < cv.dnn.Net.Net []>

--- Incoming ---
[   u'cv.dnn.Net.empty',
    u'bool',
    [],
    [],
    u'bool',
    u'Returns true if there are no layers in the network.']
ok: FUNC <bool cv.dnn.Net.empty []>

--- Incoming ---
[   u'cv.dnn.Net.getLayerId',
    u'int',
    [],
    [[u'String', u'layer', u'', []]],
    u'int',
    u"@brief Converts string name of the layer to the integer identifier.\n*  @returns id of the layer, or -1 if the layer wasn't found."]
ok: FUNC <int cv.dnn.Net.getLayerId [ARG String layer=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayerNames',
    u'vector_String',
    [],
    [],
    u'std::vector<String>',
    '']
ok: FUNC <vector_String cv.dnn.Net.getLayerNames []>

--- Incoming ---
[   u'cv.dnn.Net.getLayer',
    u'Ptr_Layer',
    [],
    [[u'LayerId', u'layerId', u'', []]],
    u'Ptr<Layer>',
    u'@brief Returns pointer to layer with specified id or name which the network use.']
ok: FUNC <Ptr_Layer cv.dnn.Net.getLayer [ARG LayerId layerId=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayerInputs',
    u'vector_Ptr_Layer',
    [],
    [[u'LayerId', u'layerId', u'', []]],
    u'std::vector<Ptr<Layer> >',
    u'@brief Returns pointers to input layers of specific layer.']
ok: FUNC <vector_Ptr_Layer cv.dnn.Net.getLayerInputs [ARG LayerId layerId=]>

--- Incoming ---
[   u'cv.dnn.Net.deleteLayer',
    u'void',
    [],
    [[u'LayerId', u'layer', u'', []]],
    u'void',
    u'@brief Delete layer for the network (not implemented yet)']
ok: FUNC <void cv.dnn.Net.deleteLayer [ARG LayerId layer=]>

--- Incoming ---
[   u'cv.dnn.Net.connect',
    u'void',
    [],
    [[u'String', u'outPin', u'', []], [u'String', u'inpPin', u'', []]],
    u'void',
    u'@brief Connects output of the first layer to input of the second layer.\n*  @param outPin descriptor of the first layer output.\n*  @param inpPin descriptor of the second layer input.\n*\n* Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n* - the first part of the template <DFN>layer_name</DFN> is sting name of the added layer.\n*   If this part is empty then the network input pseudo layer will be used;\n* - the second optional part of the template <DFN>input_number</DFN>\n*   is either number of the layer input, either label one.\n*   If this part is omitted then the first layer input will be used.\n*\n*  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()']
ok: FUNC <void cv.dnn.Net.connect [ARG String outPin=, ARG String inpPin=]>

--- Incoming ---
[   u'cv.dnn.Net.setInputsNames',
    u'void',
    [],
    [[u'vector_String', u'inputBlobNames', u'', []]],
    u'void',
    u"@brief Sets outputs names of the network input pseudo layer.\n*\n* Each net always has special own the network input pseudo layer with id=0.\n* This layer stores the user blobs only and don't make any computations.\n* In fact, this layer provides the only way to pass user data into the network.\n* As any other layer, this layer can label its outputs and this function provides an easy way to do this."]
ok: FUNC <void cv.dnn.Net.setInputsNames [ARG vector_String inputBlobNames=]>

--- Incoming ---
[   u'cv.dnn.Net.forward',
    u'Mat',
    [],
    [[u'String', u'outputName', u'String()', []]],
    u'Mat',
    u'@brief Runs forward pass to compute output of layer with name @p outputName.\n*  @param outputName name for layer which output is needed to get\n*  @return blob for first output of specified layer.\n*  @details By default runs forward pass for the whole network.']
ok: FUNC <Mat cv.dnn.Net.forward [ARG String outputName=String()]>

--- Incoming ---
[   u'cv.dnn.Net.forward',
    u'void',
    [],
    [   [u'vector_Mat', u'outputBlobs', u'', []],
        [u'String', u'outputName', u'String()', []]],
    u'void',
    u'@brief Runs forward pass to compute output of layer with name @p outputName.\n*  @param outputBlobs contains all output blobs for specified layer.\n*  @param outputName name for layer which output is needed to get\n*  @details If @p outputName is empty, runs forward pass for the whole network.']
ok: FUNC <void cv.dnn.Net.forward [ARG vector_Mat outputBlobs=, ARG String outputName=String()]>

--- Incoming ---
[   u'cv.dnn.Net.forward',
    u'void',
    [],
    [   [u'vector_Mat', u'outputBlobs', u'', []],
        [u'vector_String', u'outBlobNames', u'', []]],
    u'void',
    u'@brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n*  @param outputBlobs contains blobs for first outputs of specified layers.\n*  @param outBlobNames names for layers which outputs are needed to get']
ok: FUNC <void cv.dnn.Net.forward [ARG vector_Mat outputBlobs=, ARG vector_String outBlobNames=]>

--- Incoming ---
[   u'cv.dnn.Net.forward',
    u'void',
    [],
    [   [u'vector_vector_Mat', u'outputBlobs', u'', []],
        [u'vector_String', u'outBlobNames', u'', []]],
    u'void',
    u'@brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n*  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n*  @param outBlobNames names for layers which outputs are needed to get']
ok: FUNC <void cv.dnn.Net.forward [ARG vector_vector_Mat outputBlobs=, ARG vector_String outBlobNames=]>

--- Incoming ---
[   u'cv.dnn.Net.setInput',
    u'void',
    [],
    [[u'Mat', u'blob', u'', []], [u'String', u'name', u'""', []]],
    u'void',
    u'@brief Sets the new value for the layer output blob\n*  @param name descriptor of the updating layer output blob.\n*  @param blob new blob.\n*  @see connect(String, String) to know format of the descriptor.\n*  @note If updating blob is not empty then @p blob must have the same shape,\n*  because network reshaping is not implemented yet.']
ok: FUNC <void cv.dnn.Net.setInput [ARG Mat blob=, ARG String name=""]>

--- Incoming ---
[   u'cv.dnn.Net.setParam',
    u'void',
    [],
    [   [u'LayerId', u'layer', u'', []],
        [u'int', u'numParam', u'', []],
        [u'Mat', u'blob', u'', []]],
    u'void',
    u'@brief Sets the new value for the learned param of the layer.\n*  @param layer name or id of the layer.\n*  @param numParam index of the layer parameter in the Layer::blobs array.\n*  @param blob the new value.\n*  @see Layer::blobs\n*  @note If shape of the new blob differs from the previous shape,\n*  then the following forward pass may fail.']
ok: FUNC <void cv.dnn.Net.setParam [ARG LayerId layer=, ARG int numParam=, ARG Mat blob=]>

--- Incoming ---
[   u'cv.dnn.Net.getParam',
    u'Mat',
    [],
    [[u'LayerId', u'layer', u'', []], [u'int', u'numParam', u'0', []]],
    u'Mat',
    u'@brief Returns parameter blob of the layer.\n*  @param layer name or id of the layer.\n*  @param numParam index of the layer parameter in the Layer::blobs array.\n*  @see Layer::blobs']
ok: FUNC <Mat cv.dnn.Net.getParam [ARG LayerId layer=, ARG int numParam=0]>

--- Incoming ---
[   u'cv.dnn.Net.getUnconnectedOutLayers',
    u'vector_int',
    [],
    [],
    u'std::vector<int>',
    u'@brief Returns indexes of layers with unconnected outputs.']
ok: FUNC <vector_int cv.dnn.Net.getUnconnectedOutLayers []>

--- Incoming ---
[   u'cv.dnn.Net.getLayersShapes',
    u'void',
    [],
    [   [u'vector_MatShape', u'netInputShapes', u'', []],
        [u'vector_int*', u'layersIds', u'', []],
        [u'vector_vector_MatShape*', u'inLayersShapes', u'', []],
        [u'vector_vector_MatShape*', u'outLayersShapes', u'', []]],
    u'void',
    u"@brief Returns input and output shapes for all layers in loaded model;\n*  preliminary inferencing isn't necessary.\n*  @param netInputShapes shapes for all input blobs in net input layer.\n*  @param layersIds output parameter for layer IDs.\n*  @param inLayersShapes output parameter for input layers shapes;\n* order is the same as in layersIds\n*  @param outLayersShapes output parameter for output layers shapes;\n* order is the same as in layersIds"]
ok: FUNC <void cv.dnn.Net.getLayersShapes [ARG vector_MatShape netInputShapes=, ARG vector_int * layersIds=, ARG vector_vector_MatShape * inLayersShapes=, ARG vector_vector_MatShape * outLayersShapes=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayersShapes',
    u'void',
    [],
    [   [u'MatShape', u'netInputShape', u'', []],
        [u'vector_int*', u'layersIds', u'', []],
        [u'vector_vector_MatShape*', u'inLayersShapes', u'', []],
        [u'vector_vector_MatShape*', u'outLayersShapes', u'', []]],
    u'void',
    u'@overload']
ok: FUNC <void cv.dnn.Net.getLayersShapes [ARG MatShape netInputShape=, ARG vector_int * layersIds=, ARG vector_vector_MatShape * inLayersShapes=, ARG vector_vector_MatShape * outLayersShapes=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayerShapes',
    u'void',
    [],
    [   [u'MatShape', u'netInputShape', u'', []],
        [u'int', u'layerId', u'', []],
        [u'vector_MatShape*', u'inLayerShapes', u'', []],
        [u'vector_MatShape*', u'outLayerShapes', u'', []]],
    u'void',
    u"@brief Returns input and output shapes for layer with specified\n* id in loaded model; preliminary inferencing isn't necessary.\n*  @param netInputShape shape input blob in net input layer.\n*  @param layerId id for layer.\n*  @param inLayerShapes output parameter for input layers shapes;\n* order is the same as in layersIds\n*  @param outLayerShapes output parameter for output layers shapes;\n* order is the same as in layersIds"]
ok: FUNC <void cv.dnn.Net.getLayerShapes [ARG MatShape netInputShape=, ARG int layerId=, ARG vector_MatShape * inLayerShapes=, ARG vector_MatShape * outLayerShapes=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayerShapes',
    u'void',
    [],
    [   [u'vector_MatShape', u'netInputShapes', u'', []],
        [u'int', u'layerId', u'', []],
        [u'vector_MatShape*', u'inLayerShapes', u'', []],
        [u'vector_MatShape*', u'outLayerShapes', u'', []]],
    u'void',
    u'@overload']
ok: FUNC <void cv.dnn.Net.getLayerShapes [ARG vector_MatShape netInputShapes=, ARG int layerId=, ARG vector_MatShape * inLayerShapes=, ARG vector_MatShape * outLayerShapes=]>

--- Incoming ---
[   u'cv.dnn.Net.getFLOPS',
    u'int64',
    [],
    [[u'vector_MatShape', u'netInputShapes', u'', []]],
    u'int64',
    u'@brief Computes FLOP for whole loaded model with specified input shapes.\n* @param netInputShapes vector of shapes for all net inputs.\n* @returns computed FLOP.']
ok: FUNC <int64 cv.dnn.Net.getFLOPS [ARG vector_MatShape netInputShapes=]>

--- Incoming ---
[   u'cv.dnn.Net.getFLOPS',
    u'int64',
    [],
    [[u'MatShape', u'netInputShape', u'', []]],
    u'int64',
    u'@overload']
ok: FUNC <int64 cv.dnn.Net.getFLOPS [ARG MatShape netInputShape=]>

--- Incoming ---
[   u'cv.dnn.Net.getFLOPS',
    u'int64',
    [],
    [   [u'int', u'layerId', u'', []],
        [u'vector_MatShape', u'netInputShapes', u'', []]],
    u'int64',
    u'@overload']
ok: FUNC <int64 cv.dnn.Net.getFLOPS [ARG int layerId=, ARG vector_MatShape netInputShapes=]>

--- Incoming ---
[   u'cv.dnn.Net.getFLOPS',
    u'int64',
    [],
    [[u'int', u'layerId', u'', []], [u'MatShape', u'netInputShape', u'', []]],
    u'int64',
    u'@overload']
ok: FUNC <int64 cv.dnn.Net.getFLOPS [ARG int layerId=, ARG MatShape netInputShape=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayerTypes',
    u'void',
    [],
    [[u'vector_String', u'layersTypes', u'', ['/O']]],
    u'void',
    u'@brief Returns list of types for layer used in model.\n* @param layersTypes output parameter for returning types.']
ok: FUNC <void cv.dnn.Net.getLayerTypes [ARG vector_String layersTypes=]>

--- Incoming ---
[   u'cv.dnn.Net.getLayersCount',
    u'int',
    [],
    [[u'String', u'layerType', u'', []]],
    u'int',
    u'@brief Returns count of layers of specified type.\n* @param layerType type.\n* @returns count of layers']
ok: FUNC <int cv.dnn.Net.getLayersCount [ARG String layerType=]>

--- Incoming ---
[   u'cv.dnn.Net.getMemoryConsumption',
    u'void',
    [],
    [   [u'vector_MatShape', u'netInputShapes', u'', []],
        [u'size_t', u'weights', u'', ['/O']],
        [u'size_t', u'blobs', u'', ['/O']]],
    u'void',
    u'@brief Computes bytes number which are requered to store\n* all weights and intermediate blobs for model.\n* @param netInputShapes vector of shapes for all net inputs.\n* @param weights output parameter to store resulting bytes for weights.\n* @param blobs output parameter to store resulting bytes for intermediate blobs.']
ok: FUNC <void cv.dnn.Net.getMemoryConsumption [ARG vector_MatShape netInputShapes=, ARG size_t weights=, ARG size_t blobs=]>

--- Incoming ---
[   u'cv.dnn.Net.getMemoryConsumption',
    u'void',
    [],
    [   [u'MatShape', u'netInputShape', u'', []],
        [u'size_t', u'weights', u'', ['/O']],
        [u'size_t', u'blobs', u'', ['/O']]],
    u'void',
    u'@overload']
ok: FUNC <void cv.dnn.Net.getMemoryConsumption [ARG MatShape netInputShape=, ARG size_t weights=, ARG size_t blobs=]>

--- Incoming ---
[   u'cv.dnn.Net.getMemoryConsumption',
    u'void',
    [],
    [   [u'int', u'layerId', u'', []],
        [u'vector_MatShape', u'netInputShapes', u'', []],
        [u'size_t', u'weights', u'', ['/O']],
        [u'size_t', u'blobs', u'', ['/O']]],
    u'void',
    u'@overload']
ok: FUNC <void cv.dnn.Net.getMemoryConsumption [ARG int layerId=, ARG vector_MatShape netInputShapes=, ARG size_t weights=, ARG size_t blobs=]>

--- Incoming ---
[   u'cv.dnn.Net.getMemoryConsumption',
    u'void',
    [],
    [   [u'int', u'layerId', u'', []],
        [u'MatShape', u'netInputShape', u'', []],
        [u'size_t', u'weights', u'', ['/O']],
        [u'size_t', u'blobs', u'', ['/O']]],
    u'void',
    u'@overload']
ok: FUNC <void cv.dnn.Net.getMemoryConsumption [ARG int layerId=, ARG MatShape netInputShape=, ARG size_t weights=, ARG size_t blobs=]>

--- Incoming ---
[   u'cv.dnn.Net.getMemoryConsumption',
    u'void',
    [],
    [   [u'vector_MatShape', u'netInputShapes', u'', []],
        [u'vector_int', u'layerIds', u'', ['/O']],
        [u'vector_size_t', u'weights', u'', ['/O']],
        [u'vector_size_t', u'blobs', u'', ['/O']]],
    u'void',
    u'@brief Computes bytes number which are requered to store\n* all weights and intermediate blobs for each layer.\n* @param netInputShapes vector of shapes for all net inputs.\n* @param layerIds output vector to save layer IDs.\n* @param weights output parameter to store resulting bytes for weights.\n* @param blobs output parameter to store resulting bytes for intermediate blobs.']
ok: FUNC <void cv.dnn.Net.getMemoryConsumption [ARG vector_MatShape netInputShapes=, ARG vector_int layerIds=, ARG vector_size_t weights=, ARG vector_size_t blobs=]>

--- Incoming ---
[   u'cv.dnn.Net.getMemoryConsumption',
    u'void',
    [],
    [   [u'MatShape', u'netInputShape', u'', []],
        [u'vector_int', u'layerIds', u'', ['/O']],
        [u'vector_size_t', u'weights', u'', ['/O']],
        [u'vector_size_t', u'blobs', u'', ['/O']]],
    u'void',
    u'@overload']
ok: FUNC <void cv.dnn.Net.getMemoryConsumption [ARG MatShape netInputShape=, ARG vector_int layerIds=, ARG vector_size_t weights=, ARG vector_size_t blobs=]>

--- Incoming ---
[   u'cv.dnn.Net.enableFusion',
    u'void',
    [],
    [[u'bool', u'fusion', u'', []]],
    u'void',
    u'@brief Enables or disables layer fusion in the network.\n* @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.']
ok: FUNC <void cv.dnn.Net.enableFusion [ARG bool fusion=]>

--- Incoming ---
[   u'class cv.dnn.Importer',
    ': cv::Algorithm',
    [],
    [],
    None,
    u'@brief Small interface class for loading trained serialized models of different dnn-frameworks.']
ok: class CLASS cv.dnn::.Importer : Algorithm, name: Importer, base: Algorithm

--- Incoming ---
[   u'cv.dnn.Importer.populateNet',
    u'void',
    [],
    [[u'Net', u'net', u'', []]],
    u'void',
    u'@brief Adds loaded layers into the @p net and sets connections between them.']
ok: FUNC <void cv.dnn.Importer.populateNet [ARG Net net=]>

--- Incoming ---
[   u'cv.dnn.createCaffeImporter',
    u'Ptr_Importer',
    [],
    [   [u'String', u'prototxt', u'', []],
        [u'String', u'caffeModel', u'String()', []]],
    u'Ptr<Importer>',
    u'@brief Creates the importer of <a href="http://caffe.berkeleyvision.org">Caffe</a> framework network.\n*  @param prototxt   path to the .prototxt file with text description of the network architecture.\n*  @param caffeModel path to the .caffemodel file with learned network.\n*  @returns Pointer to the created importer, NULL in failure cases.']
ok: FUNC <Ptr_Importer cv.dnn..createCaffeImporter [ARG String prototxt=, ARG String caffeModel=String()]>

--- Incoming ---
[   u'cv.dnn.readNetFromCaffe',
    u'Net',
    [],
    [   [u'String', u'prototxt', u'', []],
        [u'String', u'caffeModel', u'String()', []]],
    u'Net',
    u'@brief Reads a network model stored in Caffe model files.\n* @details This is shortcut consisting from createCaffeImporter and Net::populateNet calls.']
ok: FUNC <Net cv.dnn..readNetFromCaffe [ARG String prototxt=, ARG String caffeModel=String()]>

--- Incoming ---
[   u'cv.dnn.readNetFromTensorflow',
    u'Net',
    [],
    [[u'String', u'model', u'', []]],
    u'Net',
    u'@brief Reads a network model stored in Tensorflow model file.\n* @details This is shortcut consisting from createTensorflowImporter and Net::populateNet calls.']
ok: FUNC <Net cv.dnn..readNetFromTensorflow [ARG String model=]>

--- Incoming ---
[   u'cv.dnn.readNetFromTorch',
    u'Net',
    [],
    [[u'String', u'model', u'', []], [u'bool', u'isBinary', u'true', []]],
    u'Net',
    u'@brief Reads a network model stored in Torch model file.\n* @details This is shortcut consisting from createTorchImporter and Net::populateNet calls.']
ok: FUNC <Net cv.dnn..readNetFromTorch [ARG String model=, ARG bool isBinary=true]>

--- Incoming ---
[   u'cv.dnn.createTensorflowImporter',
    u'Ptr_Importer',
    [],
    [[u'String', u'model', u'', []]],
    u'Ptr<Importer>',
    u'@brief Creates the importer of <a href="http://www.tensorflow.org">TensorFlow</a> framework network.\n*  @param model   path to the .pb file with binary protobuf description of the network architecture.\n*  @returns Pointer to the created importer, NULL in failure cases.']
ok: FUNC <Ptr_Importer cv.dnn..createTensorflowImporter [ARG String model=]>

--- Incoming ---
[   u'cv.dnn.createTorchImporter',
    u'Ptr_Importer',
    [],
    [[u'String', u'filename', u'', []], [u'bool', u'isBinary', u'true', []]],
    u'Ptr<Importer>',
    u'@brief Creates the importer of <a href="http://torch.ch">Torch7</a> framework network.\n*  @param filename path to the file, dumped from Torch by using torch.save() function.\n*  @param isBinary specifies whether the network was serialized in ascii mode or binary.\n*  @returns Pointer to the created importer, NULL in failure cases.\n*\n*  @warning Torch7 importer is experimental now, you need explicitly set CMake `opencv_dnn_BUILD_TORCH_IMPORTER` flag to compile its.\n*\n*  @note Ascii mode of Torch serializer is more preferable, because binary mode extensively use `long` type of C language,\n*  which has various bit-length on different systems.\n*\n* The loading file must contain serialized <a href="https://github.com/torch/nn/blob/master/doc/module.md">nn.Module</a> object\n* with importing network. Try to eliminate a custom objects from serialazing data to avoid importing errors.\n*\n* List of supported layers (i.e. object instances derived from Torch nn.Module class):\n* - nn.Sequential\n* - nn.Parallel\n* - nn.Concat\n* - nn.Linear\n* - nn.SpatialConvolution\n* - nn.SpatialMaxPooling, nn.SpatialAveragePooling\n* - nn.ReLU, nn.TanH, nn.Sigmoid\n* - nn.Reshape\n* - nn.SoftMax, nn.LogSoftMax\n*\n* Also some equivalents of these classes from cunn, cudnn, and fbcunn may be successfully imported.']
ok: FUNC <Ptr_Importer cv.dnn..createTorchImporter [ARG String filename=, ARG bool isBinary=true]>

--- Incoming ---
[   u'cv.dnn.readTorchBlob',
    u'Mat',
    [],
    [[u'String', u'filename', u'', []], [u'bool', u'isBinary', u'true', []]],
    u'Mat',
    u'@brief Loads blob which was serialized as torch.Tensor object of Torch7 framework.\n*  @warning This function has the same limitations as createTorchImporter().']
ok: FUNC <Mat cv.dnn..readTorchBlob [ARG String filename=, ARG bool isBinary=true]>

--- Incoming ---
[   u'cv.dnn.blobFromImage',
    u'Mat',
    [],
    [   [u'Mat', u'image', u'', []],
        [u'double', u'scalefactor', u'1.0', []],
        [u'Size', u'size', u'Size()', []],
        [u'Scalar', u'mean', u'Scalar()', []],
        [u'bool', u'swapRB', u'true', []]],
    u'Mat',
    u'@brief Creates 4-dimensional blob from image. Optionally resizes and crops @p image from center,\n*  subtract @p mean values, scales values by @p scalefactor, swap Blue and Red channels.\n*  @param image input image (with 1- or 3-channels).\n*  @param size spatial size for output image\n*  @param mean scalar with mean values which are subtracted from channels. Values are intended\n*  to be in (mean-R, mean-G, mean-B) order if @p image has BGR ordering and @p swapRB is true.\n*  @param scalefactor multiplier for @p image values.\n*  @param swapRB flag which indicates that swap first and last channels\n*  in 3-channel image is necessary.\n*  @details input image is resized so one side after resize is equal to corresponing\n*  dimension in @p size and another one is equal or larger. Then, crop from the center is performed.\n*  @returns 4-dimansional Mat with NCHW dimensions order.']
ok: FUNC <Mat cv.dnn..blobFromImage [ARG Mat image=, ARG double scalefactor=1.0, ARG Size size=Size(), ARG Scalar mean=Scalar(), ARG bool swapRB=true]>

--- Incoming ---
[   u'cv.dnn.blobFromImages',
    u'Mat',
    [],
    [   [u'vector_Mat', u'images', u'', []],
        [u'double', u'scalefactor', u'1.0', []],
        [u'Size', u'size', u'Size()', []],
        [u'Scalar', u'mean', u'Scalar()', []],
        [u'bool', u'swapRB', u'true', []]],
    u'Mat',
    u'@brief Creates 4-dimensional blob from series of images. Optionally resizes and\n*  crops @p images from center, subtract @p mean values, scales values by @p scalefactor,\n*  swap Blue and Red channels.\n*  @param images input images (all with 1- or 3-channels).\n*  @param size spatial size for output image\n*  @param mean scalar with mean values which are subtracted from channels. Values are intended\n*  to be in (mean-R, mean-G, mean-B) order if @p image has BGR ordering and @p swapRB is true.\n*  @param scalefactor multiplier for @p images values.\n*  @param swapRB flag which indicates that swap first and last channels\n*  in 3-channel image is necessary.\n*  @details input image is resized so one side after resize is equal to corresponing\n*  dimension in @p size and another one is equal or larger. Then, crop from the center is performed.\n*  @returns 4-dimansional Mat with NCHW dimensions order.']
ok: FUNC <Mat cv.dnn..blobFromImages [ARG vector_Mat images=, ARG double scalefactor=1.0, ARG Size size=Size(), ARG Scalar mean=Scalar(), ARG bool swapRB=true]>


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/dict.hpp =====
Namespaces: set([u'cv.dnn.experimental_dnn_v1', u'cv.dnn.<unnamed>', u'cv.dnn', u'cv', u'cv.dnn.details'])

--- Incoming ---
[   u'struct cv.dnn.DictValue',
    '',
    [],
    [],
    None,
    u'@brief This struct stores the scalar value (or array) of one of the following type: double, cv::String or int64.\n*  @todo Maybe int64 is useless because double type exactly stores at least 2^52 integers.']
ok: class CLASS cv.dnn::.DictValue : , name: DictValue, base: 

--- Incoming ---
[u'cv.dnn.DictValue.DictValue', '', [], [[u'int', u'i', u'', []]], None, '']
ok: FUNC < cv.dnn.DictValue.DictValue [ARG int i=]>

--- Incoming ---
[u'cv.dnn.DictValue.DictValue', '', [], [[u'double', u'p', u'', []]], None, '']
ok: FUNC < cv.dnn.DictValue.DictValue [ARG double p=]>

--- Incoming ---
[u'cv.dnn.DictValue.DictValue', '', [], [[u'String', u's', u'', []]], None, '']
ok: FUNC < cv.dnn.DictValue.DictValue [ARG String s=]>

--- Incoming ---
[u'cv.dnn.DictValue.isInt', u'bool', [], [], u'bool', '']
ok: FUNC <bool cv.dnn.DictValue.isInt []>

--- Incoming ---
[u'cv.dnn.DictValue.isString', u'bool', [], [], u'bool', '']
ok: FUNC <bool cv.dnn.DictValue.isString []>

--- Incoming ---
[u'cv.dnn.DictValue.isReal', u'bool', [], [], u'bool', '']
ok: FUNC <bool cv.dnn.DictValue.isReal []>

--- Incoming ---
[   u'cv.dnn.DictValue.getIntValue',
    u'int',
    [],
    [[u'int', u'idx', u'-1', []]],
    u'int',
    '']
ok: FUNC <int cv.dnn.DictValue.getIntValue [ARG int idx=-1]>

--- Incoming ---
[   u'cv.dnn.DictValue.getRealValue',
    u'double',
    [],
    [[u'int', u'idx', u'-1', []]],
    u'double',
    '']
ok: FUNC <double cv.dnn.DictValue.getRealValue [ARG int idx=-1]>

--- Incoming ---
[   u'cv.dnn.DictValue.getStringValue',
    u'String',
    [],
    [[u'int', u'idx', u'-1', []]],
    u'String',
    '']
ok: FUNC <String cv.dnn.DictValue.getStringValue [ARG int idx=-1]>


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/layer.hpp =====
Namespaces: set([u'cv.dnn.experimental_dnn_v1', u'cv.dnn.<unnamed>', u'cv.dnn', u'cv', u'cv.dnn.details'])
Ignore header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/layer.hpp


===== Header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/dnn.inl.hpp =====
Namespaces: set([u'cv.dnn.experimental_dnn_v1', u'cv.dnn.<unnamed>', u'cv.dnn', u'cv', u'cv.dnn.details'])
Ignore header: /home/bruce/work/demo/src/python/tool/opencv-3.3.0/modules/dnn/include/opencv2/dnn/dnn.inl.hpp


===== Generating... =====
CLASS cv.dnn::.Layer : Algorithm
FUNC <vector_Mat cv.dnn.Layer.finalize [ARG vector_Mat inputs=]>
java: List<Mat> finalize(List<Mat> inputs)
FUNC <void cv.dnn.Layer.finalize [ARG vector_Mat inputs=, ARG vector_Mat outputs=]>
java: void finalize(List<Mat> inputs, List<Mat> outputs)
FUNC <void cv.dnn.Layer.forward [ARG vector_Mat inputs=, ARG vector_Mat outputs=, ARG vector_Mat internals=]>
java: void forward(List<Mat> inputs, List<Mat> outputs, List<Mat> internals)
FUNC <void cv.dnn.Layer.run [ARG vector_Mat inputs=, ARG vector_Mat outputs=, ARG vector_Mat internals=]>
java: void run(List<Mat> inputs, List<Mat> outputs, List<Mat> internals)
FUNC <vector_Mat cv.dnn.Layer.get_blobs []>
java: List<Mat> get_blobs()
FUNC <void cv.dnn.Layer.set_blobs [ARG vector_Mat blobs=]>
java: void set_blobs(List<Mat> blobs)
FUNC <String cv.dnn.Layer.get_name []>
java: String get_name()
FUNC <String cv.dnn.Layer.get_type []>
java: String get_type()
CLASS ::.Dnn : 
[CONST DNN_BACKEND_DEFAULT=0, CONST DNN_BACKEND_HALIDE=1, CONST DNN_TARGET_CPU=0, CONST DNN_TARGET_OPENCL=1]
FUNC <Mat cv.dnn..blobFromImage [ARG Mat image=, ARG double scalefactor=1.0, ARG Size size=Size(), ARG Scalar mean=Scalar(), ARG bool swapRB=true]>
java: Mat blobFromImage(Mat image, double scalefactor, Size size, Scalar mean, boolean swapRB)
java: Mat blobFromImage(Mat image)
FUNC <Mat cv.dnn..blobFromImages [ARG vector_Mat images=, ARG double scalefactor=1.0, ARG Size size=Size(), ARG Scalar mean=Scalar(), ARG bool swapRB=true]>
java: Mat blobFromImages(List<Mat> images, double scalefactor, Size size, Scalar mean, boolean swapRB)
java: Mat blobFromImages(List<Mat> images)
FUNC <Mat cv.dnn..readTorchBlob [ARG String filename=, ARG bool isBinary=true]>
java: Mat readTorchBlob(String filename, boolean isBinary)
java: Mat readTorchBlob(String filename)
FUNC <Net cv.dnn..readNetFromCaffe [ARG String prototxt=, ARG String caffeModel=String()]>
java: Net readNetFromCaffe(String prototxt, String caffeModel)
java: Net readNetFromCaffe(String prototxt)
FUNC <Net cv.dnn..readNetFromTensorflow [ARG String model=]>
java: Net readNetFromTensorflow(String model)
FUNC <Net cv.dnn..readNetFromTorch [ARG String model=, ARG bool isBinary=true]>
java: Net readNetFromTorch(String model, boolean isBinary)
java: Net readNetFromTorch(String model)
FUNC <Ptr_Importer cv.dnn..createCaffeImporter [ARG String prototxt=, ARG String caffeModel=String()]>
java: Importer createCaffeImporter(String prototxt, String caffeModel)
java: Importer createCaffeImporter(String prototxt)
FUNC <Ptr_Importer cv.dnn..createTensorflowImporter [ARG String model=]>
java: Importer createTensorflowImporter(String model)
FUNC <Ptr_Importer cv.dnn..createTorchImporter [ARG String filename=, ARG bool isBinary=true]>
java: Importer createTorchImporter(String filename, boolean isBinary)
java: Importer createTorchImporter(String filename)
CLASS cv.dnn::.Importer : Algorithm
FUNC <void cv.dnn.Importer.populateNet [ARG Net net=]>
java: void populateNet(Net net)
CLASS cv.dnn::.DictValue : 
FUNC < cv.dnn.DictValue.DictValue [ARG String s=]>
java:  DictValue(String s)
FUNC < cv.dnn.DictValue.DictValue [ARG double p=]>
java:  DictValue(double p)
FUNC < cv.dnn.DictValue.DictValue [ARG int i=]>
java:  DictValue(int i)
FUNC <String cv.dnn.DictValue.getStringValue [ARG int idx=-1]>
java: String getStringValue(int idx)
java: String getStringValue()
FUNC <bool cv.dnn.DictValue.isInt []>
java: boolean isInt()
FUNC <bool cv.dnn.DictValue.isReal []>
java: boolean isReal()
FUNC <bool cv.dnn.DictValue.isString []>
java: boolean isString()
FUNC <double cv.dnn.DictValue.getRealValue [ARG int idx=-1]>
java: double getRealValue(int idx)
java: double getRealValue()
FUNC <int cv.dnn.DictValue.getIntValue [ARG int idx=-1]>
java: int getIntValue(int idx)
java: int getIntValue()
CLASS cv.dnn::.Net : 
FUNC < cv.dnn.Net.Net []>
java:  Net()
FUNC <Mat cv.dnn.Net.forward [ARG String outputName=String()]>
java: Mat forward(String outputName)
java: Mat forward()
FUNC <Mat cv.dnn.Net.getParam [ARG LayerId layer=, ARG int numParam=0]>
java: Mat getParam(DictValue layer, int numParam)
java: Mat getParam(DictValue layer)
FUNC <Ptr_Layer cv.dnn.Net.getLayer [ARG LayerId layerId=]>
java: Layer getLayer(DictValue layerId)
FUNC <bool cv.dnn.Net.empty []>
java: boolean empty()
FUNC <int cv.dnn.Net.getLayerId [ARG String layer=]>
java: int getLayerId(String layer)
FUNC <int cv.dnn.Net.getLayersCount [ARG String layerType=]>
java: int getLayersCount(String layerType)
FUNC <int64 cv.dnn.Net.getFLOPS [ARG MatShape netInputShape=]>
java: long getFLOPS(MatOfInt netInputShape)
FUNC <int64 cv.dnn.Net.getFLOPS [ARG int layerId=, ARG MatShape netInputShape=]>
java: long getFLOPS(int layerId, MatOfInt netInputShape)
FUNC <int64 cv.dnn.Net.getFLOPS [ARG int layerId=, ARG vector_MatShape netInputShapes=]>
java: long getFLOPS(int layerId, List<MatOfInt> netInputShapes)
FUNC <int64 cv.dnn.Net.getFLOPS [ARG vector_MatShape netInputShapes=]>
java: long getFLOPS(List<MatOfInt> netInputShapes)
FUNC <vector_Ptr_Layer cv.dnn.Net.getLayerInputs [ARG LayerId layerId=]>
java: List<Layer> getLayerInputs(DictValue layerId)
FUNC <vector_String cv.dnn.Net.getLayerNames []>
java: List<String> getLayerNames()
FUNC <vector_int cv.dnn.Net.getUnconnectedOutLayers []>
java: MatOfInt getUnconnectedOutLayers()
FUNC <void cv.dnn.Net.connect [ARG String outPin=, ARG String inpPin=]>
java: void connect(String outPin, String inpPin)
FUNC <void cv.dnn.Net.deleteLayer [ARG LayerId layer=]>
java: void deleteLayer(DictValue layer)
FUNC <void cv.dnn.Net.enableFusion [ARG bool fusion=]>
java: void enableFusion(boolean fusion)
FUNC <void cv.dnn.Net.forward [ARG vector_Mat outputBlobs=, ARG String outputName=String()]>
java: void forward(List<Mat> outputBlobs, String outputName)
java: void forward(List<Mat> outputBlobs)
FUNC <void cv.dnn.Net.forward [ARG vector_Mat outputBlobs=, ARG vector_String outBlobNames=]>
java: void forward(List<Mat> outputBlobs, List<String> outBlobNames)
FUNC <void cv.dnn.Net.forward [ARG vector_vector_Mat outputBlobs=, ARG vector_String outBlobNames=]>
SKIP:void forward(vector_vector_Mat outputBlobs, vector_String outBlobNames)	 due to ARG typevector_vector_Mat/I
FUNC <void cv.dnn.Net.getLayerShapes [ARG MatShape netInputShape=, ARG int layerId=, ARG vector_MatShape * inLayerShapes=, ARG vector_MatShape * outLayerShapes=]>
java: void getLayerShapes(MatOfInt netInputShape, int layerId, List<MatOfInt> inLayerShapes, List<MatOfInt> outLayerShapes)
FUNC <void cv.dnn.Net.getLayerShapes [ARG vector_MatShape netInputShapes=, ARG int layerId=, ARG vector_MatShape * inLayerShapes=, ARG vector_MatShape * outLayerShapes=]>
java: void getLayerShapes(List<MatOfInt> netInputShapes, int layerId, List<MatOfInt> inLayerShapes, List<MatOfInt> outLayerShapes)
FUNC <void cv.dnn.Net.getLayerTypes [ARG vector_String layersTypes=]>
java: void getLayerTypes(List<String> layersTypes)
FUNC <void cv.dnn.Net.getLayersShapes [ARG MatShape netInputShape=, ARG vector_int * layersIds=, ARG vector_vector_MatShape * inLayersShapes=, ARG vector_vector_MatShape * outLayersShapes=]>
SKIP:void getLayersShapes(MatShape netInputShape, vector_int* layersIds, vector_vector_MatShape* inLayersShapes, vector_vector_MatShape* outLayersShapes)	 due to ARG typevector_vector_MatShape/I
FUNC <void cv.dnn.Net.getLayersShapes [ARG vector_MatShape netInputShapes=, ARG vector_int * layersIds=, ARG vector_vector_MatShape * inLayersShapes=, ARG vector_vector_MatShape * outLayersShapes=]>
SKIP:void getLayersShapes(vector_MatShape netInputShapes, vector_int* layersIds, vector_vector_MatShape* inLayersShapes, vector_vector_MatShape* outLayersShapes)	 due to ARG typevector_vector_MatShape/I
FUNC <void cv.dnn.Net.getMemoryConsumption [ARG MatShape netInputShape=, ARG size_t weights=, ARG size_t blobs=]>
java: void getMemoryConsumption(MatOfInt netInputShape, long[] weights, long[] blobs)
FUNC <void cv.dnn.Net.getMemoryConsumption [ARG MatShape netInputShape=, ARG vector_int layerIds=, ARG vector_size_t weights=, ARG vector_size_t blobs=]>
java: void getMemoryConsumption(MatOfInt netInputShape, MatOfInt layerIds, MatOfDouble weights, MatOfDouble blobs)
FUNC <void cv.dnn.Net.getMemoryConsumption [ARG int layerId=, ARG MatShape netInputShape=, ARG size_t weights=, ARG size_t blobs=]>
java: void getMemoryConsumption(int layerId, MatOfInt netInputShape, long[] weights, long[] blobs)
FUNC <void cv.dnn.Net.getMemoryConsumption [ARG int layerId=, ARG vector_MatShape netInputShapes=, ARG size_t weights=, ARG size_t blobs=]>
java: void getMemoryConsumption(int layerId, List<MatOfInt> netInputShapes, long[] weights, long[] blobs)
FUNC <void cv.dnn.Net.getMemoryConsumption [ARG vector_MatShape netInputShapes=, ARG size_t weights=, ARG size_t blobs=]>
java: void getMemoryConsumption(List<MatOfInt> netInputShapes, long[] weights, long[] blobs)
FUNC <void cv.dnn.Net.getMemoryConsumption [ARG vector_MatShape netInputShapes=, ARG vector_int layerIds=, ARG vector_size_t weights=, ARG vector_size_t blobs=]>
java: void getMemoryConsumption(List<MatOfInt> netInputShapes, MatOfInt layerIds, MatOfDouble weights, MatOfDouble blobs)
FUNC <void cv.dnn.Net.setInput [ARG Mat blob=, ARG String name=""]>
java: void setInput(Mat blob, String name)
java: void setInput(Mat blob)
FUNC <void cv.dnn.Net.setInputsNames [ARG vector_String inputBlobNames=]>
java: void setInputsNames(List<String> inputBlobNames)
FUNC <void cv.dnn.Net.setParam [ARG LayerId layer=, ARG int numParam=, ARG Mat blob=]>
java: void setParam(DictValue layer, int numParam, Mat blob)
